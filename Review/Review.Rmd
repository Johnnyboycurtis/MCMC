---
title: "Probability and Statistics Review"
author: "Jonathan Navarrete"
date: "August 19, 2017"
output: 
  ioslides_presentation:
    theme: simplex
    smaller: true
    wide: true
    css: slides.css
    
---

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  CommonHTML: {
    scale: 95
  }
});
</script>
<script type="text/javascript" async
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



## Distribution and Density functions { .selectable }

The cumulative distribution function (CDF) of a random variable $X$ is 
$$
F_X(x) = P(X \leq x), \text{ where } x \in \mathbb{R}
$$

In most situations, we will omit the $X$ subscript and simply write $F(x)$ unless the support of $F$ is unclear. 

- A random variable $X$ is continuous if $F_X$ is a continuous function. 

- A random variable $X$ is discrete if $F_X$ is a step function. 



## Distribution and Density functions | Discrete { .selectable }

Discrete distributions can be specified by a probability mass function (pmf) $p_X(x) = P(X = x)$. If $X$ is discrete, the CDF of $X$ is
$$
F_X(x) = P(X \leq x_k) = \sum_{i=1}^{k} p(x_1) + ... + p(x_k)
$$
For discrete distributions, $f(X = x) = p(X = x) = p(x)$.


## Distribution and Density functions | Continuous { .selectable }

Unlike discrete distributions, continuous distributions do not have positive probability mass at any single point. For continuous random variables $X$ the probability density function (pdf) or density of $X$ is $f_X(x) = \frac{d}{dx} F_X(x)$. Thus, the relationship between the pdf and CDF is

$$
F_X(x) = P(X \leq x ) = \int_{- \infty}^x f_X(t) dt
$$


## Distribution and Density functions | Distribution families { .selectable }

Some pdf/pmf's form a family of distributions. One of the most common distributions is the Normal distribution
$$
f(x) = \frac{1}{\sqrt{2 \pi}  \sigma} e^{- (x - \mu)^2 \big/ 2} \text{ , } -\infty < x < \infty 
$$

The Normal distribution is part of the [**exponential family**](http://www.cs.columbia.edu/~jebara/4771/tutorials/lecture12.pdf) of distributions.


For more information, please see [**Related Distributions**](http://www.itl.nist.gov/div898/handbook/eda/section3/eda362.htm)

Also, see [**What is a Probability Distribution**](http://www.itl.nist.gov/div898/handbook/eda/section3/eda361.htm)






## Random Variables { .selectable }

Random variables are generated by a pdf/pmf. We say that a random variable $X$ is distributed by $f_X(x)$ by 
$$
X \sim f_X(x)
$$


A discrete random variable is one which may take on only a countable number of distinct values such as 0,1,2,...,etc.. Discrete random variables are usually (but not necessarily) counts. 

A continuous random variable is one which takes an infinite number of possible values. Continuous random variables are non-discrete measurements such as time, temperature, weight. 



## Expectation and Variance { .selectable }


The mean of a random variable $X$ is the *expected value* is denoted by $E[x]$. If $X$ is continuous with density $f(x)$, then

$$
E[X] = \int_{- \infty}^{\infty} x \times f(x) dx
$$

If $X$ is discrete with pmf $f(x)$, then

$$
E[X] = \sum_{x: p(x) > 0} x \times f(x)
$$

The variance of a random variable is 

$$
Var(X) = E[(X - E[X])^2] = E[X^2] - E[X]^2 
$$



## Likelihood  { .selectable }

Given a series of independent identically distributed (*iid*) random variables $\mathbf{x} = (x_1, ..., x_n)$, where $x_i \sim f(x | \theta)$, the likelihood is given by

$$
L(\theta | \mathbf{x}) = \prod_{i = 1}^n f(x_i) = f(x_1) \times f(x_2) \times ... \times f(x_n)
$$

The log-likelihood is then 

$$
l(\theta) = log(L(\theta | \mathbf{x})) = \sum_{i=1}^n log(f(x_i | \theta))
$$



## Maximum Likelihood Estimation  { .selectable }

Maximizing likelihood is a method of estimating unknown population parameters. Given a random sample $\mathbf{x} = (x_1, ..., x_n)$, we calculate the log-likelihood $l(\theta)$ and solve for $\theta$.

Other methods of parameter estimation include Method of Moments (MOM) and Bayesian Maximum A Posteriori (MAP).


Reference: [**Maximum likelihood estimation**](http://www.itl.nist.gov/div898/handbook/apr/section4/apr412.htm)




