{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The EM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now importing: \n",
      "1. numpy as np \n",
      "2. matplotlib.pyplot as plt\n",
      "3. from scipy stats\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prereqs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The EM Algorithm  \n",
    "\n",
    "\n",
    "Given a random sample of size $n$, with observed sample $\\mathbf{X} = (X_1, ..., X_m)$ and *missing* random sample $\\mathbf{Z} = Z_{m+1}, ..., Z_n$ we seek to compute \n",
    "$$\n",
    "\\hat{\\theta} = \\text{ arg max } L(\\theta | \\mathbf{X}, \\mathbf{Z}) \n",
    "$$\n",
    "Although $\\mathbf{Z}$ is unobservable, we assume that $(\\bf{X, Z}) \\sim f(\\bf{x,z} | \\theta)$.\n",
    "\n",
    "We place a conditional distribion on $\\mathbf{Z}$ given the observed data $\\bf{x}$,\n",
    "$$\n",
    "k(\\mathbf{z}| \\theta, \\mathbf{x}) = f( \\mathbf{x, z} | \\theta) / g(\\mathbf{x} | \\theta)\n",
    "$$\n",
    "\n",
    "Here we assume that that $\\mathbf{X} \\sim g(\\bf{x} | \\theta)$, where \n",
    "$$\n",
    "g(\\bf{x} | \\theta) = \\int f( \\mathbf{x,z} | \\theta ) d\\bf{z}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Denote the complete-data likelihood as $L^c(\\theta | \\mathbf{x, z})$ and the observed-data likelihood as $L(\\theta | \\mathbf{x} )$. Then, for any value of $\\theta$, $\\theta_i$\n",
    "\n",
    "$$\n",
    "log L(\\theta | \\mathbf{x}) = E[ log L^c(\\theta | \\mathbf{x, z}) ] - E [ log k( \\bf{Z} | \\theta_i, \\bf{x} ) ]\n",
    "$$\n",
    "where the expectation is with respect to $k(\\mathbf{z}| \\theta_i, \\bf{x})$. We can rewrite this as\n",
    "\n",
    "\n",
    "$$\n",
    "E[log L^c(\\theta | \\mathbf{x, z})] = log L(\\theta | \\mathbf{x}) +  E[log k(\\mathbf{Z} | \\theta_i, \\bf{x})]\n",
    "$$\n",
    "\n",
    "where our focus is concerned with maximizing $E[log L^c(\\theta | \\mathbf{x, z})]$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Denoting $E[log L^c(\\theta | \\mathbf{x, z})]$ = $Q(\\theta | \\theta_i, \\mathbf{x})$, the EM algorith iterates through values of $\\theta_i$ by maximizing $Q(\\theta | \\theta_i, \\mathbf{x})$.\n",
    "\n",
    "**The EM Algorithm**\n",
    "\n",
    "`Pick a starting value` $\\hat{\\theta_0}$\n",
    "\n",
    "`Then for i in 1:n do`\n",
    "\n",
    "`1. Compute` (E-step)\n",
    "$$\n",
    "Q(\\theta | \\theta_{i-1}, \\mathbf{x}) = E[log L^c(\\theta | \\mathbf{x, z})]\n",
    "$$\n",
    "\n",
    "`where the expectation is with respect to` $k( \\bf{Z} | \\theta_i, \\bf{x} )$\n",
    "\n",
    "`2. Maximize` $Q(\\theta | \\theta_{i-1}, \\mathbf{x})$ `in` $\\theta$ `and take`\n",
    "\n",
    "$$\n",
    "\\hat{\\theta_i} = \\text{ arg max } Q(\\theta | \\theta_{i-1}, \\mathbf{x})\n",
    "$$\n",
    "\n",
    "`repeat until convergence criteria is met`\n",
    "\n",
    "\n",
    "## The First Exercise  \n",
    "\n",
    "This exercise is taken from Flury and Zoppe, 2000, see [Exercises in EM](http://www.webpages.uidaho.edu/~stevel/565/literature/Exercise%20in%20EM.pdf).\n",
    "\n",
    "Below is the setup for the first exercise.\n",
    "\n",
    "\n",
    "\n",
    "There are two light bulb survival experiments. \n",
    "\n",
    "In the first, there are $N$ bulbs,  $y_1, ..., y_N$,  whose exact lifetimes are recorded. The lifetimes have an exponential distribution, such that $y_i \\sim Exp(\\theta).$ \n",
    "\n",
    "In the second experiment, there are $M$ bulbs, $x_1, ..., x_M$. After some time *t* > 0, a researcher walks into the room and only records how many lightbulbs are still burning out of $M$ bulbs. Depending on whether the lightbulbs are still burning or out, the results from the second experiment are right- or -left-censored. There are indicators $E_1, ..., E_M$ for each of the bulbs in the second experiment. If the bulb is still burning, $E_i = 1$, else $E_i = 0$.\n",
    "\n",
    "Given this information, our task is to solve for an MLE estimator for $\\theta$.\n",
    "\n",
    "Our first step in solving this is finding the joint likelihood for the observed and unobserved data (i.e. complete-data likelihood).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let $X_1, ... , X_M$ be the (unobserved) lifetimes for the second experiment, and let $Z = \\sum_{i=1}^ME_i$ be the number of light bulbs still burning. Thus, the observed data from both the experiments combined is $\\mathcal{Y} = (Y_1, ..., Y_N, E_1,...,E_M)$ and the unobserserved data is $\\mathcal{X} = (X_1, ..., X_M).$\n",
    "\n",
    "> The complete data log-likelihood is obtained by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\displaystyle L(\\theta| X,Y) & = \\prod^N_{i=1} \\frac{1}{\\theta} e^{y_i/\\theta} \\times \\prod^M_{i=1} \\frac{1}{\\theta} e^{x_i/\\theta}   \\\\\n",
    "\\ & = \\displaystyle \\theta^{-N} e^{-N \\bar{y} / \\theta} \\times \\theta^{-M} e^{-\\sum^M_{i=1} x_i / \\theta }  \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "## The First Exercise  \n",
    "\n",
    "And log-likelihood is obtained by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "log(L(\\theta)) & = \\displaystyle -N \\times log(\\theta) - N \\bar{y}/\\theta - M \\times log(\\theta) + \\sum^M_{i=1} x_i / \\theta  \\\\\n",
    "\\ & = \\displaystyle -N ( log(\\theta) + \\bar{y}/\\theta ) - M \\times log(\\theta) + \\sum^M_{i=1} x_i / \\theta  \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Or as written by Flury and Zoppe,\n",
    "\n",
    "$$\n",
    "log^c(L(\\theta|\\mathcal{Y,X})) = -N(log(\\theta) + \\bar{Y}/\\theta) - \\sum_{i=1}^M(log(\\theta) + X_i/\\theta ) \\tag{1}\n",
    "$$ \n",
    "\n",
    "\n",
    "## The First Exercise  \n",
    "\n",
    "\n",
    "The next step, is to take the expectation of $log(L(\\theta))$ with respect to observed data.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[log(L(\\theta)) | \\mathcal{Y},\\mathcal{X}] & = E[-N(log(\\theta) + \\bar{Y}/\\theta) - \\sum_{i=1}^M(log(\\theta) + X_i/\\theta ) | \\mathcal{Y},\\mathcal{X}] \\\\\n",
    "\\ & = -N(log(\\theta) + \\bar{Y}/\\theta) - E[\\sum_{i=1}^M(log(\\theta) + X_i/\\theta ) | \\mathcal{Y},\\mathcal{X}]   \\\\\n",
    "\\ & = -N(log(\\theta) + \\bar{Y}/\\theta) - M \\times log(\\theta) + E[\\frac{1}{\\theta}  \\sum_{i=1}^M X_i | \\mathcal{Y},\\mathcal{X}]   \\\\\n",
    "\\ & = -N(log(\\theta) + \\bar{Y}/\\theta) - M \\times log(\\theta) + \\frac{1}{\\theta} \\sum_{i=1}^M E[X_i | \\mathcal{Y},\\mathcal{X}]   \\\\\n",
    "\\ & = -N(log(\\theta) + \\bar{Y}/\\theta) - M \\times log(\\theta) + \\frac{1}{\\theta} \\sum_{i=1}^M E[X_i | E_i]   \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "> which is linear for unobserved $X_i$. But\n",
    "\n",
    "\n",
    "$$\n",
    "E[X_i | \\mathcal{Y}] = E[X_i | E_i] = \n",
    "\\begin{cases}\n",
    "    t + \\theta       & \\quad \\text{if } E_i = 1\\\\\n",
    "    \\theta - t \\frac{e^{-t/\\theta}}{1 - e^{-t/\\theta}}  & \\quad \\text{if } E_i = 0  \\tag{2} \\\\\n",
    "  \\end{cases} \n",
    "$$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For the first case, $E_i = 1$, so\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[x_i | x_i > t] & = E[x_i + t] \\\\\n",
    "\\ & = t + E[x_i] \\\\\n",
    "\\ & = t + \\theta \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For the second case, $E_i = 0$, then\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\displaystyle \\int_0^t P(X_i > x | X_i < t) \\ dx & = \\int_0^t \\frac{P(x < X_i < t)}{P(X_i < t)} \\ dx \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For the denominator, we get\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X_i < t) & = \\int_0^t \\frac{1}{\\theta} e^{- x_i / \\theta} dx \\\\\n",
    "\\ & = \\frac{1}{\\theta} (-\\theta e^{- x_i / \\theta}) |^t_0 \\\\\n",
    "\\ & = 1 - e^{- t / \\theta}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and for the numerator we obtain\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x < X_i < t) & = \\int_x^t \\frac{1}{\\theta} e^{- x_i / \\theta} dx \\\\\n",
    "\\ & = \\frac{1}{\\theta} (-\\theta e^{- x_i / \\theta}) |^t_0 \\\\\n",
    "\\ & = e^{- x / \\theta} - e^{- t / \\theta}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "Altogether, we obtain\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\displaystyle \\int_0^t P(X_i > x | X_i < t) \\ dx & = \\int_0^t \\frac{P(x < X_i < t)}{P(X_i < t)} \\ dx \\\\\n",
    "\\ & = \\displaystyle \\int_0^t \\frac{e^{- x / \\theta} - e^{- t / \\theta}}{(1 - e^{-t/\\theta})} \\ dx \\\\\n",
    "\\ & = \\displaystyle \\frac{1}{(1 - e^{-t/\\theta})} \\int_0^t (e^{- x / \\theta} - e^{- t / \\theta}) \\ dx \\\\\n",
    "\\ & = \\displaystyle \\frac{1}{(1 - e^{-t/\\theta})}  (\\int_0^t e^{- x / \\theta} - \\int_0^te^{- t / \\theta} \\ dx) \\\\\n",
    "\\ & = \\displaystyle \\frac{1}{(1 - e^{-t/\\theta})}  (\\theta (1 - e^{-t/\\theta}) - x\\times e^{- t / \\theta} |_0^t) \\\\\n",
    "\\ & = \\displaystyle   \\theta - t\\times \\frac{e^{- t / \\theta}}{1 - e^{-t/\\theta}}  \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In order to calculate EM esimates for $\\theta$, we will plug in the expected values into the log-likelihood\n",
    "\n",
    "$$\n",
    "E[X_i | \\mathcal{Y}] = E[X_i | E_i] = \n",
    "\\begin{cases}\n",
    "    t + \\theta       & \\quad \\text{if } E_i = 1\\\\\n",
    "    \\theta - t \\frac{e^{-t/\\theta}}{1 - e^{-t/\\theta}}  & \\quad \\text{if } E_i = 0\\\\\n",
    "  \\end{cases} \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log(L(\\theta)) & = \\displaystyle -N ( log(\\theta) + \\bar{y}/\\theta ) - M \\times log(\\theta) + \\sum^M_{i=1} x_i / \\theta  \\\\\n",
    "\\ & = \\displaystyle -N \\times log(\\theta) - N \\bar{y}/\\theta  - M \\times log(\\theta) + \\sum^M_{i=1} x_i / \\theta  \\\\\n",
    "\\ & = \\displaystyle -( N + M)  \\times log(\\theta) - N \\bar{y}/\\theta + \\sum^M_{i=1} x_i / \\theta  \\\\\n",
    "\\ & = \\displaystyle -( N + M)  \\times log(\\theta) - \\frac{1}{\\theta} (N \\bar{y} + \\sum^M_{i=1} x_i )  \\\\\n",
    "\\ & = -(N + M) log(\\theta) - \\frac{1}{\\theta} \\big[N \\bar{Y} + Z ( t + \\theta) + (M - Z) \\big(\\theta - t \\times \\frac{e^{- t / \\theta}}{1 - e^{-t/\\theta}} \\big)\\big] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As we iterate through estimates of $\\theta$, we will use conditioned estimates of $\\theta$ given previous estimates of $\\theta$. Such that the $j$th step consists of replacing $X_i$ in (1) by its expected value (2), using the current numerical parameter value $\\theta^{(j-1)}$. \n",
    "\n",
    "$$\n",
    "\\log(L(\\theta)) = -(N + M) log(\\theta) - \\frac{1}{\\theta} [N \\bar{Y} + Z ( t + \\theta^{(j-1)}) + (M - Z) (\\theta^{(j-1)} - t p^{(j-1)})] \\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "> where \n",
    "\n",
    "$$\n",
    "p^{(j-1)} = \\frac{e^{-t/\\theta^{(j-1)}}}{1 - e^{-t/\\theta^{(j-1)}}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## The First Exercise  \n",
    "\n",
    "\n",
    "Once we take the derivative of the log-likelihood and set it to zero, we will come up with an estimate for $\\theta$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\displaystyle\n",
    "\\frac{\\mathrm d}{\\mathrm d x} ln(L(\\theta)) & = 0 \\\\\n",
    "\\ \\displaystyle 0 & = -\\frac{(N + M)}{\\theta} + \\frac{1}{\\theta^2} \\big[N \\bar{Y} + Z ( t + \\theta^{(j-1)}) + (M - Z) \\big(\\theta^{(j-1)} - t \\times \\frac{e^{- t / \\theta^{(j-1)}}}{1 - e^{-t/\\theta^{(j-1)}}} \\big)\\big]  \\\\\n",
    "\\ \\displaystyle \\frac{(N + M)}{\\theta} & =  \\frac{1}{\\theta^2} \\big[N \\bar{Y} + Z ( t + \\theta^{(j-1)}) + (M - Z) \\big(\\theta^{(j-1)} - t \\times \\frac{e^{- t / \\theta^{(j-1)}}}{1 - e^{-t/\\theta^{(j-1)}}} \\big) \\big] \\\\\n",
    "\\ \\displaystyle \\theta & =  \\big[N \\bar{Y} + Z ( t + \\theta^{(j-1)}) + (M - Z) \\big(\\theta^{(j-1)} - t \\times \\frac{e^{- t / \\theta^{(j-1)}}}{1 - e^{-t/\\theta^{(j-1)}}} \\big)\\big] \\ / \\ (N+M) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Thus, for each *j*th M-step, we will calculate\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta^{(j)} & = f(\\theta^{(j-1)}) \\\\\n",
    "\\ \\displaystyle \\theta & =  \\big[N \\bar{Y} + Z ( t + \\theta^{(j-1)}) + (M - Z) \\big(\\theta^{(j-1)} - t \\times \\frac{e^{- t / \\theta^{(j-1)}}}{1 - e^{-t/\\theta^{(j-1)}}} \\big)\\big] \\ / \\ (N+M) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "theta = 5 ## theta\n",
    "\n",
    "t = 5 ## time cut off\n",
    "N = 100 ## sample size of ex 1\n",
    "M = 50 ## sample size of ex 2\n",
    "y = np.random.exponential(size=N, scale = theta) ## first experiment\n",
    "x = np.random.exponential(size=M, scale = theta) ## second experiment\n",
    "x = np.sort(x)\n",
    "E = np.int64(x > t)  ## 0 & 1\n",
    "\n",
    "ybar = np.mean(y)\n",
    "Z = np.sum(E)\n",
    "t = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.066172364533033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.17740132763\n",
      "1 4.95589783696\n",
      "2 5.06975690426\n",
      "3 5.08603680591\n",
      "4 5.08835807946\n",
      "5 5.08868893005\n",
      "6 5.08873608351\n",
      "7 5.08874280385\n",
      "8 5.08874376164\n",
      "9 5.08874389814\n"
     ]
    }
   ],
   "source": [
    "theta_j = 0.1\n",
    "theta_jp1 = 0.5\n",
    "for i in range(10):\n",
    "    theta_j = theta_jp1\n",
    "    p = (np.exp(-t/theta_j)/(1 - np.exp(-t/theta_j)))\n",
    "    theta_jp1 = (N*ybar + Z*( t + theta_j) + (M-Z)*(theta_j - t*p) ) / (N+M)\n",
    "    print(i, theta_jp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.08874389814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.127762652795429"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compare results\n",
    "print(theta_jp1) ## EM theta estimate\n",
    "np.mean(y) ## compare against MLE from observed data\n",
    "np.mean(np.concatenate((y, x))) ## compare against complete-data\n",
    "## note, results will vary if you remove seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM Normal Example  \n",
    "\n",
    "Suppose $X = (x_1, ..., x_n)^T$ is a random sample from $N(\\mu,1).$ Let the observations be in order such that $x_1 < x_2 < ... < x_n$. \n",
    "Suppose that after time $c$, values are censored or missing, such that only $x_1, ..., x_m$ are observed, and $x_{m+1}, ..., x_n$ are unobserved. \n",
    "Then, $r = (n - m)$ would be the quantity missing. We will use the EM and MCEM algorithms to find approximations for $\\mu$.\n",
    "Let $Z = (x_{m+1}, ..., x_n)^T$.\n",
    "\n",
    "First, construct the likelihood function.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\mu | x) & = \\prod^m f(x_i | \\mu, 1) \\times \\prod^r f(z_i | \\mu, 1) \\\\\n",
    "\\ & = (2 \\pi )^{-n/2} exp(-\\frac{1}{2} \\sum_{i=1}^m (x_i - \\mu)^2) \\times exp(-\\frac{1}{2} \\sum_{i=1}^m (z_i - \\mu)^2) \\\\\n",
    "\\ & \\propto exp(-\\frac{1}{2} \\sum_{i=1}^m (x_i - \\mu)^2) \\times exp(-\\frac{1}{2} \\sum_{i=1}^m (z_i - \\mu)^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "## EM Normal Example  \n",
    "\n",
    "The log-likelihood is then \n",
    "\n",
    "$$\n",
    "ln(L(\\mu | X)) = -\\frac{1}{2} \\sum_{i=1}^m (x_i - \\mu)^2) - \\frac{1}{2} \\sum_{i=1}^m (z_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "We now find the conditional expectation $E[z_i | X]$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[z_i | X] & =  E[z_i | x > c] = \\int_c^{\\infty} \\frac{P(x_i > x | x_i > c)}{P(x_i > c)}   \\\\\n",
    "\\ & = \\mu + \\sigma \\frac{\\phi(c - \\mu)}{1 - \\Phi(c - \\mu)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For notes on this derivation, see [Truncated Normal Distribution](https://en.wikipedia.org/wiki/Truncated_normal_distribution#Moments)\n",
    "\n",
    "\n",
    "\n",
    "## EM Normal Example  \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q(\\mu | \\mu_t) & = -\\frac{1}{2} \\sum_{i=1}^m (x_i - \\mu)^2) - \\sum E[z_i | X] \\\\\n",
    "\\ & =   -\\frac{1}{2} \\sum_{i=1}^m (x_i - \\mu)^2) - \\sum E[z | X] \\\\\n",
    "\\ & =   -\\frac{1}{2} \\sum_{i=1}^m (x_i - \\mu)^2) - (n-m) E[z | X] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The MLE for $\\mu$ is then,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{t+1} & =  \\frac{m \\bar{x}}{n} + \\frac{(n - m) E[z | X]}{n} \\\\\n",
    "\\ & = \\frac{m \\bar{x}}{n} + \\frac{(n - m) (\\mu_t)}{n} + \\frac{(n-m) \\phi(c - \\mu_t)}{n \\Phi(c-\\mu_t)} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2345)\n",
    "n = 100\n",
    "mu = 4\n",
    "sd = 1\n",
    "x = np.random.normal(size=n, loc=mu, scale=sd) ## generate some data\n",
    "c = 5 ## time cut off\n",
    "w = x[x < c] ## obtain samples before time cut off\n",
    "m = np.sum(x < c) ## number of observed samples\n",
    "wbar = np.mean(w) ## observed mean\n",
    "r = n - m ## difference in sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0023998029\n"
     ]
    }
   ],
   "source": [
    "## EM Normal Example  \n",
    "from scipy import stats\n",
    "dnorm = stats.norm.pdf ## get density values\n",
    "pnorm = stats.norm.cdf ## get tail probabilities\n",
    "\n",
    "N = 200\n",
    "mu_new = wbar\n",
    "results = []\n",
    "for i in range(N):\n",
    "    results.append(mu_new)\n",
    "    mu_old = mu_new\n",
    "    mu_new = m*wbar/n + (r*mu_old/n) + (r/n)*sd*(dnorm(c - mu_old))/(1 - pnorm(c - mu_old))  ## r/n instead of 1/n\n",
    "\n",
    "print(results[-1]) ## last value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEaCAYAAAAG87ApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgcREcnC4CAiIln+Dx+tC2pRAErvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f578b5d5390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hlines(xmin=0, xmax=N, y=mu, linestyles=\"--\")\n",
    "plot(range(1, N+1), results, ylim=(3.5, 4.5), \n",
    "     title = \"EM Algorithm estimates\", xlabel = \"Iterations\",\n",
    "    ylabel = r\"$\\hat{\\mu}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Monte Carlo EM \n",
    "\n",
    "A MC flavor of the EM algorithm\n",
    "\n",
    "1. Draw missing data sets $\\mathbf{Z_1, Z_2, ..., Z_m} \\sim f_{Z|X}(z | x, \\theta_i)$ where each $\\mathbf{Z_i}$ is a vector of all missing values needed to complete the observed data set $( \\mathbf{X, Z} )$.\n",
    "\n",
    "2. Calculate $\\bar{Q}(\\theta | \\theta_{i-1}, X, \\mathbf{Z_1, ..., Z_m}) = \\frac{1}{m} \\sum_{i=1}^m Q(\\theta | \\theta_{i-1}, X, \\mathbf{Z_i} )$\n",
    "\n",
    "\n",
    "\n",
    "## EM Normal Example | Monte Carlo EM \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2345)\n",
    "n = 100\n",
    "mu = 4\n",
    "sd = 1\n",
    "x = np.random.normal(size = n, loc = mu, scale=sd)  #rnorm(n, mu, sd)\n",
    "c = 5\n",
    "w = x[x < c]\n",
    "m = np.sum(x < c)\n",
    "wbar = np.mean(w)\n",
    "r = n - m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 10\n",
    "N = 100\n",
    "mu_new = wbar\n",
    "results = numeric(N)\n",
    "for(i in 1:N){\n",
    "    results[i] = mu_new\n",
    "    mu_old = mu_new\n",
    "    ## abs(N(0,1)) + mu_old + (c - mu_old) to *approximate*\n",
    "    ## the truncated samples we need\n",
    "    Z = matrix(data = (c - mu_old) + (mu_old +  abs(rnorm(n = r*M, mean = 0, sd = 1))), \n",
    "        nrow = r, ncol = M)\n",
    "    mu_new = (m*wbar/n) + mean(colMeans(Z))*r/n\n",
    "    M = M + 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnorm = np.random.normal\n",
    "M = 10\n",
    "N = 100 ## number of iterations\n",
    "mu_new = wbar\n",
    "results = []\n",
    "for i in range(N):\n",
    "    mu_old = mu_new\n",
    "    ## abs(N(0,1)) + mu_old + (c - mu_old) to *approximate*\n",
    "    ## the truncated samples we need\n",
    "    Z = (c - mu_old) + (mu_old - np.abs(rnorm(size = (r, M), loc=0, scale=1)))\n",
    "    mu_new = (m*wbar/n) + np.mean( np.mean(Z, axis=0))*r/n\n",
    "    results.append(mu_new)\n",
    "    M = M + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEaCAYAAAAG87ApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f578ae1c080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## EM Normal Example| Monte Carlo EM   \n",
    "plt.hlines(xmin = 1, xmax=N, y = mu, linestyles=\"--\", colors='blue')\n",
    "plt.hlines(xmin = 1, xmax=N, y = wbar, linestyles=\"--\", colors='green')\n",
    "plot(x = range(1, N+1), y = results, xlabel = \"Iterations\",\n",
    "     title = \"Monte Carlo EM\", ylabel = r\"$\\hat{\\mu}$\", ylim = (2, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MC EM estimates lie closer to true theoretical value than simple MLE estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
